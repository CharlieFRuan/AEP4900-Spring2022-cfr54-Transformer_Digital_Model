{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_lorenz_enn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "75e1510848ff81b2a8a3022c3bfac472ed28a49a56e1422a056d525171f2408b"
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPjTnCG-v2Z6",
        "outputId": "a7da634c-78c7-4102-cd6e-70e47714a1c2"
      },
      "source": [
        "\"\"\"\n",
        "Notebook for training the embedding model for the Lorenz system.\n",
        "=====\n",
        "Distributed by: Notre Dame SCAI Lab (MIT Liscense)\n",
        "- Associated publication:\n",
        "url: https://arxiv.org/abs/2010.03957\n",
        "doi: \n",
        "github: https://github.com/zabaras/transformer-physx\n",
        "=====\n",
        "\"\"\"\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 28 23:58:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34XMtg9FZFql"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuqsYQ_2S4kq"
      },
      "source": [
        "Use pip to install from [PyPI](https://pypi.org/project/trphysx/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvm518_H3AK7",
        "outputId": "fd2fdf69-39b1-4734-aa1b-0207cca60e6b"
      },
      "source": [
        "!pip install trphysx==0.0.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: trphysx==0.0.7 in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (1.9.0+cu102)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (3.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (3.0.12)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->trphysx==0.0.7) (1.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->trphysx==0.0.7) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoBoGx0J0LtZ"
      },
      "source": [
        "Mount google drive and create a folder to work in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K0hSst0b2Ak",
        "outputId": "8c31ace4-d0a1-47a5-c4d6-8275203d7eda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zaXL-m8xEx9",
        "outputId": "a6a686ea-1f21-4a02-c32e-af294db14ebd"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/\n",
        "% mkdir -p transformer_physx/lorenz\n",
        "% cd transformer_physx/lorenz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n",
            "/content/gdrive/MyDrive/transformer_physx/lorenz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MK_h8wF0Rr4"
      },
      "source": [
        "Now lets download the training and validation data for the lorenz system. Info on wget from [Google drive](https://stackoverflow.com/questions/37453841/download-a-file-from-google-drive-using-wget). This will eventually be update to zenodo repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NtZ02zD0EKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca992ae-2885-4e2f-8dd2-b73ee905290f"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU702uo6xIQQ",
        "outputId": "63a24ca1-ac6b-4798-b318-68e0a7c0cc58"
      },
      "source": [
        "!wget -O ./data/lorenz_training_rk.hdf5 \"https://drive.google.com/uc?export=download&id=1vGTGzaqEZxxuLN9K-PUrYw9SLWttdDYd\"\n",
        "!wget -O ./data/lorenz_valid_rk.hdf5 \"https://drive.google.com/uc?export=download&id=1bxFzKg8tSagE8kXWGm2mtaJ4gPsKJ8sI\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-29 00:09:06--  https://drive.google.com/uc?export=download&id=1vGTGzaqEZxxuLN9K-PUrYw9SLWttdDYd\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.15.78, 2607:f8b0:4004:80a::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.15.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rk4l6obvlpuuld5ggjv0pjgefhr94dak/1627517325000/01559412990587423567/*/1vGTGzaqEZxxuLN9K-PUrYw9SLWttdDYd?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-29 00:09:06--  https://doc-0o-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rk4l6obvlpuuld5ggjv0pjgefhr94dak/1627517325000/01559412990587423567/*/1vGTGzaqEZxxuLN9K-PUrYw9SLWttdDYd?e=download\n",
            "Resolving doc-0o-0o-docs.googleusercontent.com (doc-0o-0o-docs.googleusercontent.com)... 172.217.15.97, 2607:f8b0:4004:811::2001\n",
            "Connecting to doc-0o-0o-docs.googleusercontent.com (doc-0o-0o-docs.googleusercontent.com)|172.217.15.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-hdf]\n",
            "Saving to: ‘./data/lorenz_training_rk.hdf5’\n",
            "\n",
            "./data/lorenz_train     [  <=>               ]  12.78M  45.1MB/s    in 0.3s    \n",
            "\n",
            "2021-07-29 00:09:07 (45.1 MB/s) - ‘./data/lorenz_training_rk.hdf5’ saved [13403392]\n",
            "\n",
            "--2021-07-29 00:09:07--  https://drive.google.com/uc?export=download&id=1bxFzKg8tSagE8kXWGm2mtaJ4gPsKJ8sI\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.2.110, 2607:f8b0:4004:80a::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.2.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/61de44t5fuit8dqdan1uij21dal5j9rm/1627517325000/01559412990587423567/*/1bxFzKg8tSagE8kXWGm2mtaJ4gPsKJ8sI?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-29 00:09:07--  https://doc-14-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/61de44t5fuit8dqdan1uij21dal5j9rm/1627517325000/01559412990587423567/*/1bxFzKg8tSagE8kXWGm2mtaJ4gPsKJ8sI?e=download\n",
            "Resolving doc-14-0o-docs.googleusercontent.com (doc-14-0o-docs.googleusercontent.com)... 172.217.15.97, 2607:f8b0:4004:811::2001\n",
            "Connecting to doc-14-0o-docs.googleusercontent.com (doc-14-0o-docs.googleusercontent.com)|172.217.15.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1598976 (1.5M) [application/x-hdf]\n",
            "Saving to: ‘./data/lorenz_valid_rk.hdf5’\n",
            "\n",
            "./data/lorenz_valid 100%[===================>]   1.52M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-07-29 00:09:08 (16.1 MB/s) - ‘./data/lorenz_valid_rk.hdf5’ saved [1598976/1598976]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCHiYnrdZN95"
      },
      "source": [
        "# Transformer-PhysX Lorenz System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDVeeJHn11Ir"
      },
      "source": [
        "Train the embedding model.\n",
        "First import necessary modules from trphysx. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNGVZQ-o1gsH"
      },
      "source": [
        "import sys, os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "from trphysx.config.configuration_auto import AutoPhysConfig\n",
        "from trphysx.embedding.embedding_auto import AutoEmbeddingModel\n",
        "from trphysx.embedding.training import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEft0ltg4swx"
      },
      "source": [
        "Training arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R8QQ0cj4qR9"
      },
      "source": [
        "argv = []\n",
        "argv = argv + [\"--exp_name\", \"lorenz\"]\n",
        "argv = argv + [\"--training_h5_file\", \"./data/lorenz_training_rk.hdf5\"]\n",
        "argv = argv + [\"--eval_h5_file\", \"./data/lorenz_valid_rk.hdf5\"]\n",
        "argv = argv + [\"--batch_size\", '512']\n",
        "argv = argv + [\"--block_size\", \"16\"]\n",
        "argv = argv + [\"--n_train\", \"2048\"]\n",
        "argv = argv + [\"--n_eval\", \"64\"]\n",
        "argv = argv + [\"--epochs\", \"100\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcBfHEh540f6",
        "outputId": "a9dc0eeb-013c-4825-9f41-833bc8d242f7"
      },
      "source": [
        "args = EmbeddingParser().parse(args=argv)  \n",
        "\n",
        "if(torch.cuda.is_available()):\n",
        "    use_cuda = \"cuda\"\n",
        "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch device:{}\".format(args.device))\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch device:cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Fel9vqZVsH"
      },
      "source": [
        "## Initializing Datasets and Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjxiqD3lF98_"
      },
      "source": [
        "Now we can use the auto classes to initialized the predefined configs, dataloaders and models. This may take a bit!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcpC9Fy243RN",
        "outputId": "3b629e8f-b0cb-405f-fd74-ac992c47d92c"
      },
      "source": [
        " # Load transformer config file\n",
        "config = AutoPhysConfig.load_config(args.exp_name)\n",
        "dataloader = AutoDataHandler.load_data_handler(args.exp_name)\n",
        "\n",
        "# Set up data-loaders\n",
        "training_loader = dataloader.createTrainingLoader(\n",
        "    args.training_h5_file, \n",
        "    block_size=args.block_size, \n",
        "    stride=args.stride, \n",
        "    ndata=args.n_train, \n",
        "    batch_size=args.batch_size)\n",
        "testing_loader = dataloader.createTestingLoader(\n",
        "    args.eval_h5_file, \n",
        "    block_size=32, \n",
        "    ndata=args.n_eval, \n",
        "    batch_size=8)\n",
        "\n",
        "# Set up model\n",
        "model = AutoEmbeddingModel.init_trainer(args.exp_name, config).to(args.device)\n",
        "mu, std = dataloader.norm_params\n",
        "model.embedding_model.mu = mu.to(args.device)\n",
        "model.embedding_model.std = std.to(args.device)\n",
        "if args.epoch_start > 1:\n",
        "  model.load_model(args.ckpt_dir, args.epoch_start)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/29/2021 00:10:18 - INFO - trphysx.embedding.training.enn_data_handler -   Creating training loader.\n",
            "07/29/2021 00:10:53 - INFO - trphysx.embedding.training.enn_data_handler -   Creating testing loader\n",
            "07/29/2021 00:10:57 - INFO - trphysx.embedding.embedding_lorenz -   Number of embedding parameters: 36192\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auDiMVZ5UfNz"
      },
      "source": [
        "Initialize optimizer and scheduler. Feel free to change if you want to experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnrtuKdhGuWQ"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr*0.995**(args.epoch_start-1), weight_decay=1e-8)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.995)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It_LLGQIZe0b"
      },
      "source": [
        "## Training the Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2XPKfYTUuXf"
      },
      "source": [
        "Train the model. No visualization here, just boring numbers. This notebook only trains for 100 epochs for brevity, feel free to train longer. The test loss here is only the recovery loss MSE(x - decode(encode(x))) and does not reflect the quality of the Koopman dynamics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ic9DFQcUWpm",
        "outputId": "7532fecf-c988-45b2-a664-b91cf4bef7cb"
      },
      "source": [
        "trainer = EmbeddingTrainer(model, args, (optimizer, scheduler))\n",
        "trainer.train(training_loader, testing_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/29/2021 00:11:42 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 1: Training loss 40621124.000, Lr 0.00100\n",
            "07/29/2021 00:11:42 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 1: Test loss: 0.11\n",
            "07/29/2021 00:11:45 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 2: Training loss 733321.812, Lr 0.00099\n",
            "07/29/2021 00:11:47 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 3: Training loss 529222.688, Lr 0.00099\n",
            "07/29/2021 00:11:49 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 4: Training loss 425458.938, Lr 0.00099\n",
            "07/29/2021 00:11:52 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 5: Training loss 652651.062, Lr 0.00098\n",
            "07/29/2021 00:11:52 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 5: Test loss: 0.10\n",
            "07/29/2021 00:11:54 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 6: Training loss 783782.562, Lr 0.00098\n",
            "07/29/2021 00:11:56 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 7: Training loss 378522.938, Lr 0.00097\n",
            "07/29/2021 00:11:59 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 8: Training loss 300511.156, Lr 0.00097\n",
            "07/29/2021 00:12:01 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 9: Training loss 279688.094, Lr 0.00096\n",
            "07/29/2021 00:12:03 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 10: Training loss 574017.188, Lr 0.00096\n",
            "07/29/2021 00:12:03 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 10: Test loss: 0.10\n",
            "07/29/2021 00:12:06 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 11: Training loss 328817.156, Lr 0.00095\n",
            "07/29/2021 00:12:08 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 12: Training loss 244459.859, Lr 0.00095\n",
            "07/29/2021 00:12:10 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 13: Training loss 201832.031, Lr 0.00094\n",
            "07/29/2021 00:12:13 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 14: Training loss 297025.562, Lr 0.00094\n",
            "07/29/2021 00:12:15 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 15: Training loss 211454.812, Lr 0.00093\n",
            "07/29/2021 00:12:15 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 15: Test loss: 0.11\n",
            "07/29/2021 00:12:17 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 16: Training loss 230410.922, Lr 0.00093\n",
            "07/29/2021 00:12:20 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 17: Training loss 340248.875, Lr 0.00092\n",
            "07/29/2021 00:12:22 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 18: Training loss 286692.438, Lr 0.00092\n",
            "07/29/2021 00:12:24 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 19: Training loss 210121.219, Lr 0.00091\n",
            "07/29/2021 00:12:26 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 20: Training loss 187763.312, Lr 0.00091\n",
            "07/29/2021 00:12:26 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 20: Test loss: 0.11\n",
            "07/29/2021 00:12:29 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 21: Training loss 173717.359, Lr 0.00090\n",
            "07/29/2021 00:12:31 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 22: Training loss 161858.594, Lr 0.00090\n",
            "07/29/2021 00:12:33 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 23: Training loss 153142.219, Lr 0.00090\n",
            "07/29/2021 00:12:35 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 24: Training loss 146916.953, Lr 0.00089\n",
            "07/29/2021 00:12:38 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 25: Training loss 139697.547, Lr 0.00089\n",
            "07/29/2021 00:12:38 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 25: Test loss: 0.11\n",
            "07/29/2021 00:12:38 - INFO - trphysx.embedding.training.enn_trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/29/2021 00:12:40 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 26: Training loss 134319.859, Lr 0.00088\n",
            "07/29/2021 00:12:42 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 27: Training loss 339473.688, Lr 0.00088\n",
            "07/29/2021 00:12:44 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 28: Training loss 191062.750, Lr 0.00087\n",
            "07/29/2021 00:12:47 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 29: Training loss 153706.266, Lr 0.00087\n",
            "07/29/2021 00:12:49 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 30: Training loss 133756.156, Lr 0.00086\n",
            "07/29/2021 00:12:49 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 30: Test loss: 0.10\n",
            "07/29/2021 00:12:51 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 31: Training loss 117164.656, Lr 0.00086\n",
            "07/29/2021 00:12:53 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 32: Training loss 100381.094, Lr 0.00086\n",
            "07/29/2021 00:12:56 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 33: Training loss 178065.625, Lr 0.00085\n",
            "07/29/2021 00:12:58 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 34: Training loss 146255.562, Lr 0.00085\n",
            "07/29/2021 00:13:00 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 35: Training loss 115386.414, Lr 0.00084\n",
            "07/29/2021 00:13:00 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 35: Test loss: 0.10\n",
            "07/29/2021 00:13:03 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 36: Training loss 102444.945, Lr 0.00084\n",
            "07/29/2021 00:13:05 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 37: Training loss 92413.992, Lr 0.00083\n",
            "07/29/2021 00:13:07 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 38: Training loss 84267.852, Lr 0.00083\n",
            "07/29/2021 00:13:10 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 39: Training loss 309969.406, Lr 0.00083\n",
            "07/29/2021 00:13:12 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 40: Training loss 211985.656, Lr 0.00082\n",
            "07/29/2021 00:13:12 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 40: Test loss: 0.10\n",
            "07/29/2021 00:13:15 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 41: Training loss 141925.422, Lr 0.00082\n",
            "07/29/2021 00:13:17 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 42: Training loss 120304.484, Lr 0.00081\n",
            "07/29/2021 00:13:19 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 43: Training loss 111143.297, Lr 0.00081\n",
            "07/29/2021 00:13:22 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 44: Training loss 99963.688, Lr 0.00081\n",
            "07/29/2021 00:13:24 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 45: Training loss 95617.625, Lr 0.00080\n",
            "07/29/2021 00:13:24 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 45: Test loss: 0.11\n",
            "07/29/2021 00:13:26 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 46: Training loss 89460.148, Lr 0.00080\n",
            "07/29/2021 00:13:28 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 47: Training loss 85131.773, Lr 0.00079\n",
            "07/29/2021 00:13:31 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 48: Training loss 81913.117, Lr 0.00079\n",
            "07/29/2021 00:13:33 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 49: Training loss 98877.406, Lr 0.00079\n",
            "07/29/2021 00:13:35 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 50: Training loss 129710.531, Lr 0.00078\n",
            "07/29/2021 00:13:35 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 50: Test loss: 0.10\n",
            "07/29/2021 00:13:35 - INFO - trphysx.embedding.training.enn_trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/29/2021 00:13:38 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 51: Training loss 91726.039, Lr 0.00078\n",
            "07/29/2021 00:13:40 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 52: Training loss 82034.055, Lr 0.00077\n",
            "07/29/2021 00:13:42 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 53: Training loss 76683.141, Lr 0.00077\n",
            "07/29/2021 00:13:44 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 54: Training loss 69648.883, Lr 0.00077\n",
            "07/29/2021 00:13:47 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 55: Training loss 61252.891, Lr 0.00076\n",
            "07/29/2021 00:13:47 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 55: Test loss: 0.10\n",
            "07/29/2021 00:13:49 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 56: Training loss 121598.602, Lr 0.00076\n",
            "07/29/2021 00:13:51 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 57: Training loss 92184.406, Lr 0.00076\n",
            "07/29/2021 00:13:53 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 58: Training loss 87949.227, Lr 0.00075\n",
            "07/29/2021 00:13:56 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 59: Training loss 73238.797, Lr 0.00075\n",
            "07/29/2021 00:13:58 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 60: Training loss 63366.121, Lr 0.00074\n",
            "07/29/2021 00:13:58 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 60: Test loss: 0.10\n",
            "07/29/2021 00:14:00 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 61: Training loss 102759.781, Lr 0.00074\n",
            "07/29/2021 00:14:02 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 62: Training loss 150250.312, Lr 0.00074\n",
            "07/29/2021 00:14:05 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 63: Training loss 91833.266, Lr 0.00073\n",
            "07/29/2021 00:14:07 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 64: Training loss 64959.902, Lr 0.00073\n",
            "07/29/2021 00:14:09 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 65: Training loss 78551.133, Lr 0.00073\n",
            "07/29/2021 00:14:09 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 65: Test loss: 0.10\n",
            "07/29/2021 00:14:12 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 66: Training loss 71582.914, Lr 0.00072\n",
            "07/29/2021 00:14:14 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 67: Training loss 65907.750, Lr 0.00072\n",
            "07/29/2021 00:14:17 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 68: Training loss 62868.059, Lr 0.00071\n",
            "07/29/2021 00:14:19 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 69: Training loss 61217.406, Lr 0.00071\n",
            "07/29/2021 00:14:21 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 70: Training loss 61236.789, Lr 0.00071\n",
            "07/29/2021 00:14:21 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 70: Test loss: 0.10\n",
            "07/29/2021 00:14:24 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 71: Training loss 59513.438, Lr 0.00070\n",
            "07/29/2021 00:14:26 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 72: Training loss 55972.543, Lr 0.00070\n",
            "07/29/2021 00:14:28 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 73: Training loss 54648.172, Lr 0.00070\n",
            "07/29/2021 00:14:30 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 74: Training loss 53407.664, Lr 0.00069\n",
            "07/29/2021 00:14:33 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 75: Training loss 54011.520, Lr 0.00069\n",
            "07/29/2021 00:14:33 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 75: Test loss: 0.10\n",
            "07/29/2021 00:14:33 - INFO - trphysx.embedding.training.enn_trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/29/2021 00:14:35 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 76: Training loss 64337.031, Lr 0.00069\n",
            "07/29/2021 00:14:37 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 77: Training loss 60271.312, Lr 0.00068\n",
            "07/29/2021 00:14:39 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 78: Training loss 55284.316, Lr 0.00068\n",
            "07/29/2021 00:14:42 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 79: Training loss 51975.051, Lr 0.00068\n",
            "07/29/2021 00:14:44 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 80: Training loss 49493.098, Lr 0.00067\n",
            "07/29/2021 00:14:44 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 80: Test loss: 0.10\n",
            "07/29/2021 00:14:46 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 81: Training loss 48472.410, Lr 0.00067\n",
            "07/29/2021 00:14:48 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 82: Training loss 47305.211, Lr 0.00067\n",
            "07/29/2021 00:14:51 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 83: Training loss 43588.230, Lr 0.00066\n",
            "07/29/2021 00:14:53 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 84: Training loss 50842.477, Lr 0.00066\n",
            "07/29/2021 00:14:55 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 85: Training loss 79520.117, Lr 0.00066\n",
            "07/29/2021 00:14:55 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 85: Test loss: 0.11\n",
            "07/29/2021 00:14:57 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 86: Training loss 45303.441, Lr 0.00065\n",
            "07/29/2021 00:15:00 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 87: Training loss 40672.004, Lr 0.00065\n",
            "07/29/2021 00:15:02 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 88: Training loss 38021.887, Lr 0.00065\n",
            "07/29/2021 00:15:04 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 89: Training loss 34733.277, Lr 0.00064\n",
            "07/29/2021 00:15:06 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 90: Training loss 32223.352, Lr 0.00064\n",
            "07/29/2021 00:15:06 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 90: Test loss: 0.10\n",
            "07/29/2021 00:15:09 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 91: Training loss 30897.541, Lr 0.00064\n",
            "07/29/2021 00:15:11 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 92: Training loss 30077.629, Lr 0.00063\n",
            "07/29/2021 00:15:13 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 93: Training loss 59433.457, Lr 0.00063\n",
            "07/29/2021 00:15:16 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 94: Training loss 48097.961, Lr 0.00063\n",
            "07/29/2021 00:15:18 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 95: Training loss 50217.312, Lr 0.00062\n",
            "07/29/2021 00:15:18 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 95: Test loss: 0.10\n",
            "07/29/2021 00:15:20 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 96: Training loss 53961.289, Lr 0.00062\n",
            "07/29/2021 00:15:23 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 97: Training loss 51166.016, Lr 0.00062\n",
            "07/29/2021 00:15:25 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 98: Training loss 44619.934, Lr 0.00061\n",
            "07/29/2021 00:15:27 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 99: Training loss 42182.289, Lr 0.00061\n",
            "07/29/2021 00:15:30 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 100: Training loss 40237.457, Lr 0.00061\n",
            "07/29/2021 00:15:30 - INFO - trphysx.embedding.training.enn_trainer -   Epoch 100: Test loss: 0.10\n",
            "07/29/2021 00:15:30 - INFO - trphysx.embedding.training.enn_trainer -   Checkpointing model, optimizer and scheduler.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3ZEE4ixh8nr"
      },
      "source": [
        "Check your Google drive for checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7J5GgEFh_8t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}