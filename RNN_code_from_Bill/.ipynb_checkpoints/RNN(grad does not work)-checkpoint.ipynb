{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "94a7aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c92988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('exp_io_data\\CoupledPendula_mean_in7_out7_Tmax1.0_data.npz')\n",
    "for key, val in data.items():\n",
    "\n",
    "    exec(key +'=val')\n",
    "x=xlist\n",
    "y=exp_out_list\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7fe5e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24749702 0.02014035 0.8485794  ... 0.08696669 0.99749106 0.38496768]\n",
      " [0.75097805 0.60711515 0.67705935 ... 0.44351715 0.26912165 0.6546309 ]\n",
      " [0.5515969  0.85570264 0.12367398 ... 0.65876925 0.5144654  0.21687716]\n",
      " ...\n",
      " [0.7910753  0.15300226 0.25244486 ... 0.79041374 0.23180968 0.36545432]\n",
      " [0.8996175  0.3548531  0.558233   ... 0.77378803 0.30139804 0.52732176]\n",
      " [0.45920014 0.6914123  0.7981772  ... 0.7037045  0.4136985  0.35502923]]\n"
     ]
    }
   ],
   "source": [
    "x_in=x[:,0:7]\n",
    "x_para=x[:,7:14]\n",
    "#print(x_in)\n",
    "#print(x_para)\n",
    "def pre_processing_x(x):\n",
    "    n,d=x.shape\n",
    "    n= int(n/2)\n",
    "    d= int(d/2)\n",
    "    x_in=x[:,0:d]\n",
    "    x_para=x[:,d:2*d]\n",
    "    x_train=x_in[0:n:]\n",
    "    x_test=x_in[n:2*n,:]\n",
    "    x_train_para=x_para[0:n,:]\n",
    "    x_test_para=x_para[n:n*2,:]\n",
    "    return x_train,x_test,x_train_para, x_test_para\n",
    "a,b,c,d=pre_processing_x(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6fc4b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2000, 7)\n",
      "(30, 2000, 7)\n",
      "torch.Size([2000, 30, 14])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_x=y[0,:,:,:,0]\n",
    "y_v=y[0,:,:,:,1]/30\n",
    "print(y_x.shape)\n",
    "print(y_v.shape)\n",
    "\n",
    "y_new=np.concatenate((y_x,y_v),axis=2)\n",
    "y_new=torch.from_numpy(y_new)\n",
    "y_new=torch.transpose(y_new,0,1)\n",
    "# print(y_new[1,1:2,:])\n",
    "# print(y_new[1,2:3,:])\n",
    "print(y_new.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c153c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (rnn): RNN(14, 14, num_layers=5, batch_first=True)\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(14,14, 5,batch_first=True)\n",
    "        self.fc = nn.Linear(14,14)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ =self.rnn(x)\n",
    "        #out =out[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "net2 = Net2()\n",
    "print(net2)\n",
    "\n",
    "\n",
    "#out0=net(in0)\n",
    "#out1=net(out0)...\n",
    "# full_data=30*14\n",
    "# net(in5)=full_data[0:5,:]\n",
    "#out0=net(in0)\n",
    "#y_target=full_data[1:6,:]\n",
    "#loss = mse(y_target, net(in5) )\n",
    "#loss= sum (out[i]-in[i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6283fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001F48DC31430>\n"
     ]
    }
   ],
   "source": [
    "print(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f687626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14])\n",
      "torch.Size([14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14])\n",
      "torch.Size([14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14])\n",
      "torch.Size([14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14])\n",
      "torch.Size([14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14])\n",
      "torch.Size([14])\n",
      "torch.Size([14, 14])\n",
      "torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "params = list(net2.parameters())\n",
    "print(len(params))\n",
    "for i in range(22):\n",
    "    \n",
    "    print(params[i].size())\n",
    "for j in [1,5,9,13,17]:\n",
    "    params[i]=torch.zeros(14,14,requires_grad=False)\n",
    "    #print(params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9490aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 5, 14])\n",
      "torch.Size([2000, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = y_new[:,0:5,:]\n",
    "print(input.shape)\n",
    "out = net2(input)\n",
    "#print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d116d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 5, 14])\n",
      "torch.Size([2000, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = y_new[:,0:5,:]\n",
    "print(input.shape)\n",
    "out = net2(input)\n",
    "#print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72a86957",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.zero_grad()\n",
    "out.backward(torch.randn(2000,5,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1acdb550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 5, 14])\n",
      "tensor(0.3633, grad_fn=<MseLossBackward>)\n",
      "torch.Size([2000, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "target= y_new[:,1:6,:]\n",
    "print(target.shape)\n",
    "criterion=nn.MSELoss()\n",
    "loss=criterion(out,target)\n",
    "print(loss)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e5a53db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3205, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3206, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3205, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3205, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3204, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(params, lr=0.01, betas=(0.9, 0.999), eps=1e-09, weight_decay=0.1, amsgrad=False)  #adam optimizer\n",
    "    \n",
    "for i in range(20):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net2(input)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cba61ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 5, 14])\n",
      "tensor([[[-0.1028, -0.0126, -0.1508,  ...,  0.0603,  0.1758, -0.0927],\n",
      "         [-0.0980, -0.0121, -0.1457,  ...,  0.0578,  0.1693, -0.0891],\n",
      "         [-0.0976, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0888],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0887],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1685, -0.0887]],\n",
      "\n",
      "        [[-0.1028, -0.0126, -0.1508,  ...,  0.0603,  0.1758, -0.0927],\n",
      "         [-0.0980, -0.0121, -0.1457,  ...,  0.0578,  0.1693, -0.0891],\n",
      "         [-0.0976, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0888],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0887],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1685, -0.0887]],\n",
      "\n",
      "        [[-0.1028, -0.0126, -0.1508,  ...,  0.0603,  0.1758, -0.0927],\n",
      "         [-0.0980, -0.0121, -0.1457,  ...,  0.0578,  0.1693, -0.0891],\n",
      "         [-0.0976, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0888],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0887],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1685, -0.0887]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1028, -0.0126, -0.1508,  ...,  0.0603,  0.1758, -0.0927],\n",
      "         [-0.0980, -0.0121, -0.1457,  ...,  0.0578,  0.1693, -0.0891],\n",
      "         [-0.0976, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0888],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0887],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1685, -0.0887]],\n",
      "\n",
      "        [[-0.1028, -0.0126, -0.1508,  ...,  0.0603,  0.1758, -0.0927],\n",
      "         [-0.0980, -0.0121, -0.1457,  ...,  0.0578,  0.1693, -0.0891],\n",
      "         [-0.0976, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0888],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0887],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1685, -0.0887]],\n",
      "\n",
      "        [[-0.1028, -0.0126, -0.1508,  ...,  0.0603,  0.1758, -0.0927],\n",
      "         [-0.0980, -0.0121, -0.1457,  ...,  0.0578,  0.1693, -0.0891],\n",
      "         [-0.0976, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0888],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1686, -0.0887],\n",
      "         [-0.0975, -0.0120, -0.1452,  ...,  0.0575,  0.1685, -0.0887]]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "output_plot=output[:,:]\n",
    "print(output_plot.shape)\n",
    "target_plot= target\n",
    "print(output_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae78d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y_pred')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output_plot.detach().flatten(), target_plot.detach().numpy().flatten(), '.')\n",
    "plt.title('Training')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c198fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9185, 0.8238, 0.9963,  ..., 0.6682, 0.7984, 0.1572],\n",
      "        [0.3933, 0.9606, 0.9643,  ..., 0.7520, 0.4876, 0.8830],\n",
      "        [0.6237, 0.5434, 0.0358,  ..., 0.9932, 0.3677, 0.0729],\n",
      "        ...,\n",
      "        [0.4289, 0.7778, 0.2352,  ..., 0.7652, 0.4831, 0.2972],\n",
      "        [0.2022, 0.3456, 0.6055,  ..., 0.7885, 0.4216, 0.8429],\n",
      "        [0.8430, 0.8307, 0.3663,  ..., 0.3736, 0.5766, 0.7607]])\n"
     ]
    }
   ],
   "source": [
    "x_test=torch.tensor(x[1000:2000,:])\n",
    "x_para_test=torch.from_numpy(x_para[1000:2000,:])\n",
    "print(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122b0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 14])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-2e6bfa592afc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_test_new\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtest_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-43eb8f69c712>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m#out =out[:,-1,:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    202\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "y_test=y_new[1000:2000,6:7,:]\n",
    "print(y_test.shape)\n",
    "y_test_new=torch.transpose(y_test,1,2).squeeze(2)\n",
    "\n",
    "test_out=net2(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c25c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7489bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dt_exp_comparison(yexp, ypred):\n",
    "\n",
    "    fig, axs = plt.subplots(nrows = 3, ncols = 3, figsize = [10,8], dpi = 100, sharex=True, sharey=True)\n",
    "    for i in range(9):\n",
    "        plt.sca(axs.flatten()[i])\n",
    "        plt.plot(ypred[i], '.-', lw = 1, c = 'k', alpha = 0.5, label = 'digital twin prediction')\n",
    "        plt.plot(yexp[i], '.-', lw = 1, c = 'b', alpha = 0.5, label = 'experimental outcome')\n",
    "        plt.xlabel('# pendulum')\n",
    "        plt.ylabel('output angle')\n",
    "        plt.title(f'Initial conditions {i}')\n",
    "        plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('img/coupled_pendula_dt_examples.png')\n",
    "    plt.show()\n",
    "    \n",
    "#plot_dt_exp_comparison(y_test_new,2*test_out.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f07a100a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-012f559573ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_dt_exp_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_out' is not defined"
     ]
    }
   ],
   "source": [
    "plot_dt_exp_comparison(y_test_new,2*test_out.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb087b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2375,  0.2631, -0.4102,  0.3369,  0.7218,  0.0728, -0.1361,\n",
      "          -0.6703, -0.0438, -0.0732,  0.3423, -0.7693,  0.2935, -0.3053,\n",
      "           0.2523, -0.0571, -0.0202,  0.2989, -0.5673,  0.5073],\n",
      "         [ 0.6162,  0.1850,  0.4126,  0.7775, -0.0137, -0.0534,  0.3354,\n",
      "           0.7826,  0.0203, -0.7898, -0.4899, -0.4363,  0.2901, -0.1991,\n",
      "           0.8144, -0.7364, -0.2497, -0.1143,  0.2171, -0.6417],\n",
      "         [-0.4599, -0.0467, -0.2275, -0.4104, -0.5177, -0.3929,  0.2770,\n",
      "           0.8107,  0.1556, -0.0995, -0.1703, -0.8356, -0.2047,  0.1082,\n",
      "          -0.4893, -0.3708,  0.2517, -0.5033,  0.1679, -0.7449]],\n",
      "\n",
      "        [[ 0.5826, -0.2345, -0.1166, -0.1942, -0.4757,  0.3322, -0.5826,\n",
      "          -0.3270,  0.2118, -0.0024, -0.1701, -0.6327,  0.2515,  0.1649,\n",
      "          -0.0095, -0.0376, -0.2996, -0.0382, -0.7207, -0.1265],\n",
      "         [-0.0549, -0.0493,  0.2682,  0.3365, -0.1387,  0.2228, -0.3334,\n",
      "           0.1602, -0.3064, -0.0831,  0.2582, -0.5007,  0.0114, -0.0103,\n",
      "           0.2658, -0.5293,  0.2877, -0.3719, -0.4715, -0.1208],\n",
      "         [-0.3125, -0.3016, -0.0204,  0.0847, -0.0077,  0.4658, -0.2452,\n",
      "           0.1091, -0.3852, -0.0755,  0.0776, -0.1404, -0.0011,  0.4005,\n",
      "           0.2406, -0.8163,  0.1532, -0.4261, -0.3656, -0.2762]],\n",
      "\n",
      "        [[ 0.5054, -0.4136, -0.2962,  0.5057,  0.4392, -0.2878, -0.4731,\n",
      "          -0.0941, -0.6872,  0.1761, -0.0538, -0.4454, -0.3259,  0.0369,\n",
      "           0.0860, -0.3703,  0.2451, -0.2202, -0.4112,  0.1488],\n",
      "         [ 0.4517, -0.3042,  0.0795,  0.3457, -0.0103,  0.0512, -0.3927,\n",
      "           0.0322, -0.4201, -0.2221, -0.1264, -0.3993, -0.1371,  0.1127,\n",
      "           0.2265, -0.4175, -0.0568, -0.0578, -0.5661,  0.0356],\n",
      "         [ 0.3689, -0.2880, -0.0834,  0.2502, -0.3059,  0.0103, -0.1698,\n",
      "           0.0342, -0.4672, -0.2911, -0.0625, -0.1386, -0.1101,  0.2326,\n",
      "           0.3360, -0.5214, -0.4251,  0.0659, -0.5549,  0.0030]],\n",
      "\n",
      "        [[ 0.5662, -0.3924,  0.2271, -0.0280, -0.6562, -0.1666, -0.6108,\n",
      "          -0.1970, -0.3824,  0.0868,  0.2201, -0.2143, -0.5242,  0.4802,\n",
      "           0.0935, -0.4634,  0.0200, -0.1722, -0.6964, -0.0753],\n",
      "         [ 0.3622, -0.3244, -0.2337,  0.1243,  0.4384, -0.3291, -0.1694,\n",
      "          -0.0844, -0.5373,  0.0572,  0.3523, -0.6900, -0.3768, -0.0565,\n",
      "          -0.1246, -0.3254, -0.0832, -0.4805, -0.3972,  0.5157],\n",
      "         [ 0.5297, -0.2339,  0.2699,  0.2406, -0.4258, -0.2221, -0.5343,\n",
      "          -0.1382, -0.3427, -0.1200,  0.0430, -0.1669, -0.3750,  0.3879,\n",
      "           0.3565, -0.6322, -0.0713, -0.2206, -0.5769, -0.0319]],\n",
      "\n",
      "        [[ 0.3071, -0.5472, -0.3569,  0.1084, -0.3758,  0.1539, -0.4219,\n",
      "          -0.1505, -0.4635,  0.0516,  0.3275, -0.5479, -0.3174, -0.0627,\n",
      "           0.2701, -0.5778, -0.3365, -0.0482, -0.7135, -0.2598],\n",
      "         [ 0.1495, -0.4303, -0.2355, -0.1277, -0.3989, -0.3064, -0.5847,\n",
      "          -0.1632, -0.2620, -0.0534,  0.2587, -0.5978, -0.1610,  0.0980,\n",
      "          -0.0823, -0.2441,  0.0828, -0.1782, -0.4260,  0.1333],\n",
      "         [ 0.4282, -0.3873, -0.5432,  0.2686,  0.0479, -0.4013, -0.4194,\n",
      "           0.1998, -0.5793,  0.2235,  0.2342, -0.6091, -0.2176, -0.0401,\n",
      "           0.0412, -0.6277, -0.0740, -0.3508, -0.5368,  0.2850]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c01430",
   "metadata": {},
   "source": [
    "params2 = list(net2.parameters())\n",
    "print(len(params2))\n",
    "print(params2[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b558da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=torch.tensor(x)\n",
    "input = x_data\n",
    "out = net2(input)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ad80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=y1[0:1000,:,:]\n",
    "target_new=target.view(1000,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-06, weight_decay=0.1, amsgrad=False)  #adam optimizer\n",
    "    \n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net2(input)\n",
    "    loss = criterion(output, target_new)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684b295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
